{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSMv_biWU0Km"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adds new types of ids\n",
        "#assigns new ids starting from 0 to both annotations and images in val.json and train.json respectively\n",
        "def transformIds(annotations_df, images_df):\n",
        "\n",
        "  annotations_df_new = annotations_df.copy()\n",
        "  images_df_new = images_df.copy()\n",
        "\n",
        "  newImageIds = np.array(list(range(images_df['id'].size)))\n",
        "  old_ids = images_df['id'].to_numpy()\n",
        "  imgeIdsChangeMap = dict([(old_ids[index], index) for index in list(range(images_df['id'].size))])\n",
        "\n",
        "  newAnnotationIds = np.array(list(range(annotations_df['id'].size)))\n",
        "\n",
        "  images_df_new['id'] = newImageIds\n",
        "  images_df_new['frame_id'] = images_df_new['id'].apply(lambda id : id % 150)\n",
        "  images_df_new['first_frame_image_id'] = images_df_new['id'].apply(lambda id: ((id // 150) * 150))\n",
        "\n",
        "  annotations_df_new['id'] = newAnnotationIds\n",
        "\n",
        "  annotations_df_new['image_id'] = annotations_df_new['image_id'].apply(lambda id : imgeIdsChangeMap[id])\n",
        "\n",
        "  return annotations_df_new, images_df_new"
      ],
      "metadata": {
        "id": "Oal4rQZgU979"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#returns images and and annotations refering a list of image_ids\n",
        "def getPartialAnnotations(annotations, images, sequenceSample):\n",
        "  image_ids = np.array([])\n",
        "  for sequence in sequenceSample:\n",
        "    try:\n",
        "      sequence_id = int(sequence)\n",
        "      image_ids = np.concatenate((image_ids, np.array(list(range((sequence_id - 1)*150 + 1, sequence_id * 150 + 1)))))\n",
        "    except ValueError:\n",
        "      print(f'the dir name {sequence} couldnt be cast as int')\n",
        "  image_ids_set = set(image_ids)\n",
        "  filtered_annotations = annotations[annotations['image_id'].isin(image_ids_set)]\n",
        "  filtered_images = images[images['id'].isin(image_ids_set)]\n",
        "  return filtered_annotations, filtered_images"
      ],
      "metadata": {
        "id": "jmA-j1iPU_3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copies images from a set of sequences into a new folder\n",
        "def copyPartialSequence(subdirectoryPath, sequenceSample, dsPath):\n",
        "  for sequence in sequenceSample:\n",
        "    for imageName in os.listdir(os.path.join(dsPath, sequence)):\n",
        "      shutil.copy(os.path.join(dsPath, sequence, imageName), os.path.join(subdirectoryPath, imageName))"
      ],
      "metadata": {
        "id": "pMvJlLCxVDc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#receives bbox as relative values for x_center, y_center, wdth, heigh\n",
        "#returns bbox as absolute values for x_left, y_top, width, height\n",
        "def adjustBoundingBox(bbox):\n",
        "  x , y, w ,h = [value * 1024 for value in bbox]\n",
        "  return [x - (w/2), y - (h/2), w, h]"
      ],
      "metadata": {
        "id": "-LJRiv_0VDzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#receives dataset as formatted in this project\n",
        "#returns dataset formatted as documented in https://github.com/timmeinhardt/trackformer/blob/main/docs/TRAIN.md\n",
        "def createCOCODataset(dataset_path, annotations_path, output_dir_path):\n",
        "\n",
        "  if(not os.path.exists(output_dir_path)):\n",
        "    os.mkdir(output_dir_path)\n",
        "\n",
        "  with open(annotations_path, 'r') as file:\n",
        "    annotationsDict = json.load(file)\n",
        "\n",
        "\n",
        "  images_df = pd.DataFrame(annotationsDict['images'])\n",
        "  images_df['file_name'] = images_df['file_name'].apply(lambda name : name.split('/')[-1])\n",
        "  images_df['seq_length'] = 150\n",
        "\n",
        "  annotations_df = pd.DataFrame(annotationsDict['annotations'])\n",
        "\n",
        "  annotations_df = annotations_df.rename(columns={'label': 'track_id'})\n",
        "  annotations_df = annotations_df.sort_values(by='track_id')\n",
        "  annotations_df['bbox'] = annotations_df['bbox'].apply(lambda bbox : adjustBoundingBox(bbox))\n",
        "\n",
        "  annotationsDict['annotations'] = annotations_df.to_dict(orient='records')\n",
        "  annotationsDict['images'] = images_df.to_dict(orient='records')\n",
        "\n",
        "  sequences = np.array(os.listdir(dataset_path))\n",
        "\n",
        "  train_proportion = 0.8\n",
        "  num_samples = int(len(sequences) * train_proportion)\n",
        "\n",
        "  train_sequences = sequences[np.random.choice(len(sequences), size=num_samples, replace=False)]\n",
        "\n",
        "  val_sequences = sequences[~np.isin(sequences, train_sequences)]\n",
        "\n",
        "  train_ds_path = os.path.join(output_dir_path, 'train')\n",
        "\n",
        "  if(not os.path.exists(train_ds_path)):\n",
        "    os.mkdir(train_ds_path)\n",
        "\n",
        "  val_ds_path = os.path.join(output_dir_path, 'val')\n",
        "\n",
        "  if(not os.path.exists(val_ds_path)):\n",
        "    os.mkdir(val_ds_path)\n",
        "\n",
        "\n",
        "  copyPartialSequence(train_ds_path, train_sequences, dataset_path)\n",
        "\n",
        "  copyPartialSequence(val_ds_path, val_sequences, dataset_path)\n",
        "\n",
        "  annotations_dir_path = os.path.join(output_dir_path, 'annotations')\n",
        "\n",
        "  if(not os.path.exists(annotations_dir_path)):\n",
        "    os.mkdir(annotations_dir_path)\n",
        "\n",
        "\n",
        "  train_annotations_df, train_images_df = getPartialAnnotations(annotations_df, images_df, train_sequences)\n",
        "  val_annotations_df, val_images_df = getPartialAnnotations(annotations_df, images_df, val_sequences)\n",
        "\n",
        "  train_annotations_df, train_images_df = transformIds(train_annotations_df, train_images_df)\n",
        "  val_annotations_df, val_images_df = transformIds(val_annotations_df, val_images_df)\n",
        "\n",
        "  del annotationsDict['info']\n",
        "\n",
        "  val_annotations_dict = annotationsDict.copy()\n",
        "  train_annotations_dict = annotationsDict.copy()\n",
        "\n",
        "  val_annotations_dict['annotations'] = val_annotations_df.to_dict(orient='records')\n",
        "  val_annotations_dict['images'] = val_images_df.to_dict(orient='records')\n",
        "  train_annotations_dict['annotations'] = train_annotations_df.to_dict(orient='records')\n",
        "  train_annotations_dict['images'] = train_images_df.to_dict(orient='records')\n",
        "\n",
        "  train_annotations_dict['sequences'] = np.sort(train_sequences).tolist()\n",
        "  train_annotations_dict['frame_range'] = {\"start\": 0.0,\n",
        "                                          \"end\": 1.0}\n",
        "  train_annotations_dict['type'] = 'instances'\n",
        "\n",
        "\n",
        "  val_annotations_dict['sequences'] = np.sort(val_sequences).tolist()\n",
        "  val_annotations_dict['frame_range'] = {\"start\": 0.0,\n",
        "                                         \"end\": 1.0}\n",
        "  val_annotations_dict['type'] = 'instances'\n",
        "\n",
        "  train_annotations_filename = \"train.json\"\n",
        "  with open(os.path.join(annotations_dir_path, train_annotations_filename), 'w') as outfile:\n",
        "    json.dump(train_annotations_dict, outfile, indent=4)\n",
        "\n",
        "  val_annotations_filename = \"val.json\"\n",
        "  with open(os.path.join(annotations_dir_path, val_annotations_filename), 'w') as outfile:\n",
        "    json.dump(val_annotations_dict, outfile, indent=4)"
      ],
      "metadata": {
        "id": "0WJf20HhVD8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Steps\n",
        "since the Documentation in https://github.com/timmeinhardt/trackformer/blob/main/docs/TRAIN.md is not complete it is necessary to also include the sequences used for training/validation in seperate directories in the dataset and provide the original annotations json. These adjustments were made manually."
      ],
      "metadata": {
        "id": "KNiAefaPXwNn"
      }
    }
  ]
}